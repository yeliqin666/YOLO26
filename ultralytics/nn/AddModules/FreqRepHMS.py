"""
ðŸ”¥ RepHMS_FreqLALK ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆYOLO26 å…¼å®¹ç‰ˆï¼‰
âœ… ä¿®å¤äº† MultiScaleFreqGate å°ºå¯¸ä¸åŒ¹é…
âœ… ä¿®å¤äº†æ··åˆç‰ˆé€šé“å†²çª
âœ… ä¿®å¤äº† BatchNorm åœ¨ batch_size=1 æ—¶çš„é”™è¯¯
âœ… å…¼å®¹ YOLO parse_model çš„å‚æ•°ä¼ é€’æ–¹å¼
âœ… æ”¯æŒ c1 != c2 çš„é€šé“é€‚é…
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

# ============================================================================
# å¯¼å…¥ Conv æ¨¡å—ï¼ˆç”¨äºŽé€šé“é€‚é…ï¼‰
# ============================================================================
try:
    from ultralytics.nn.modules.conv import Conv
except ImportError:
    # å¦‚æžœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
    class Conv(nn.Module):
        def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
            super().__init__()
            self.conv = nn.Conv2d(c1, c2, k, s, p or k // 2, groups=g, dilation=d, bias=False)
            self.bn = nn.BatchNorm2d(c2)
            self.act = nn.SiLU() if act else nn.Identity()

        def forward(self, x):
            return self.act(self.bn(self.conv(x)))


# ============================================================================
# ä¼˜åŒ–1: è‡ªé€‚åº”FreqGate - å¯å­¦ä¹ çš„é¢‘åŸŸæƒé‡
# ============================================================================

class AdaptiveFreqGate(nn.Module):
    """
    è‡ªé€‚åº”é¢‘åŸŸé—¨æŽ§ï¼šå¢žåŠ å¯å­¦ä¹ çš„å¼€å…³ï¼Œè®©ç½‘ç»œå†³å®šé¢‘åŸŸç­›é€‰çš„å¼ºåº¦
    """
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        mid_channels = max(8, channels // reduction)
        
        # ðŸ”¥ ä¿®å¤ï¼šç§»é™¤æ‰€æœ‰å½’ä¸€åŒ–å±‚ï¼ˆé¿å… batch_size=1 ä¸”ç©ºé—´ç»´åº¦ä¸º 1x1 çš„é—®é¢˜ï¼‰
        # Gate æ¨¡å—æœ¬èº«å¾ˆè½»é‡ï¼ŒSigmoid å·²æä¾›èŒƒå›´é™åˆ¶ï¼Œä¸éœ€è¦å½’ä¸€åŒ–
        self.fc = nn.Sequential(
            nn.Conv2d(channels, mid_channels, 1, bias=True),
            nn.SiLU(),
            nn.Conv2d(mid_channels, channels, 1, bias=True),
            nn.Sigmoid()
        )
        
        # ðŸ”¥ å¯å­¦ä¹ çš„é—¨æŽ§å¼ºåº¦ (0-1ä¹‹é—´)
        self.gate_strength = nn.Parameter(torch.tensor(0.5))
    
    def forward(self, x):
        low_freq_info = self.avg_pool(x)
        freq_weight = self.fc(low_freq_info)
        
        # è‡ªé€‚åº”æ··åˆï¼šè®©ç½‘ç»œå­¦ä¹ é¢‘åŸŸç­›é€‰çš„é‡è¦æ€§
        gated = x * freq_weight
        return (1 - self.gate_strength) * x + self.gate_strength * gated


# ============================================================================
# ä¼˜åŒ–2: å¤šé¢‘æ®µFreqGate - åˆ†åˆ«å¤„ç†ä¸åŒé¢‘æ®µ
# ============================================================================

class MultiScaleFreqGate(nn.Module):
    """
    å¤šå°ºåº¦é¢‘åŸŸé—¨æŽ§ï¼šåˆ†åˆ«æ•æ‰ä½Žé¢‘/ä¸­é¢‘/é«˜é¢‘ä¿¡æ¯
    """
    def __init__(self, channels, reduction=16):
        super().__init__()
        mid_channels = max(8, channels // reduction)
        
        # ä½Žé¢‘é—¨æŽ§ (å…¨å±€) - ç§»é™¤å½’ä¸€åŒ–å±‚
        self.low_pool = nn.AdaptiveAvgPool2d(1)
        self.low_gate = nn.Sequential(
            nn.Conv2d(channels, mid_channels, 1, bias=True),
            nn.SiLU(),
            nn.Conv2d(mid_channels, channels, 1, bias=True),
        )
        
        # ä¸­é¢‘é—¨æŽ§ (å±€éƒ¨) - ç§»é™¤å½’ä¸€åŒ–å±‚
        self.mid_pool = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)
        self.mid_gate = nn.Sequential(
            nn.Conv2d(channels, mid_channels, 1, bias=True),
            nn.SiLU(),
            nn.Conv2d(mid_channels, channels, 1, bias=True),
        )
        
        # é«˜é¢‘æƒé‡å­¦ä¹  - ç§»é™¤å½’ä¸€åŒ–å±‚
        self.high_gate = nn.Sequential(
            nn.Conv2d(channels, mid_channels, 1, bias=True),
            nn.SiLU(),
            nn.Conv2d(mid_channels, channels, 1, bias=True),
        )
        
        # èžåˆæƒé‡ - ç§»é™¤å½’ä¸€åŒ–å±‚
        self.fusion = nn.Sequential(
            nn.Conv2d(channels * 3, channels, 1, bias=True),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        B, C, H, W = x.shape
        
        # ä½Žé¢‘åˆ†é‡ - ä¿®å¤ï¼šéœ€è¦ä¸Šé‡‡æ ·åˆ°åŽŸå§‹å°ºå¯¸
        low_freq_pooled = self.low_pool(x)  # [B, C, 1, 1]
        low_freq = self.low_gate(low_freq_pooled)  # [B, C, 1, 1]
        low_freq = F.interpolate(low_freq, size=(H, W), mode='bilinear', align_corners=False)  # [B, C, H, W]
        
        # ä¸­é¢‘åˆ†é‡
        mid_freq = self.mid_pool(x)  # [B, C, H, W]
        mid_freq = self.mid_gate(mid_freq)  # [B, C, H, W]
        
        # é«˜é¢‘åˆ†é‡ (åŽŸå§‹ - ä½Žé¢‘è¿‘ä¼¼)
        low_approx = F.interpolate(low_freq_pooled, size=(H, W), mode='bilinear', align_corners=False)
        high_freq = x - low_approx  # [B, C, H, W]
        high_freq = self.high_gate(high_freq)  # [B, C, H, W]
        
        # èžåˆæ‰€æœ‰é¢‘æ®µ
        freq_features = torch.cat([low_freq, mid_freq, high_freq], dim=1)  # [B, 3*C, H, W]
        freq_weight = self.fusion(freq_features)  # [B, C, H, W]
        
        return x * freq_weight


# ============================================================================
# ä¼˜åŒ–3: å±‚çº§åŒ–FreqGate - ä¸åŒæ·±åº¦ç”¨ä¸åŒå¼ºåº¦
# ============================================================================

class HierarchicalFreqGate(nn.Module):
    """
    å±‚çº§åŒ–é¢‘åŸŸé—¨æŽ§ï¼šæµ…å±‚å¼±ç­›é€‰ï¼Œæ·±å±‚å¼ºç­›é€‰
    """
    def __init__(self, channels, reduction=16, layer_depth=0, max_depth=2):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        mid_channels = max(8, channels // reduction)
        
        # ðŸ”¥ ä¿®å¤ï¼šç§»é™¤å½’ä¸€åŒ–å±‚
        self.fc = nn.Sequential(
            nn.Conv2d(channels, mid_channels, 1, bias=True),
            nn.SiLU(),
            nn.Conv2d(mid_channels, channels, 1, bias=True),
            nn.Sigmoid()
        )
        
        # å±‚çº§åŒ–å¼ºåº¦ï¼šéšæ·±åº¦é€’å¢ž
        self.strength = 0.2 + 0.6 * (layer_depth / max(max_depth, 1))
    
    def forward(self, x):
        low_freq_info = self.avg_pool(x)
        freq_weight = self.fc(low_freq_info)
        gated = x * freq_weight
        
        return (1 - self.strength) * x + self.strength * gated


# ============================================================================
# ç®€åŒ–çš„FreqGate (ä¿æŒä½ çš„åŽŸç‰ˆ)
# ============================================================================

class FreqGate(nn.Module):
    """åŽŸç‰ˆFreqGate - ç®€å•é«˜æ•ˆ"""
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        mid_channels = max(8, channels // reduction)
        
        # ðŸ”¥ ä¿®å¤ï¼šç§»é™¤å½’ä¸€åŒ–å±‚
        self.fc = nn.Sequential(
            nn.Conv2d(channels, mid_channels, 1, bias=True),
            nn.SiLU(),
            nn.Conv2d(mid_channels, channels, 1, bias=True),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        low_freq_info = self.avg_pool(x)
        freq_weight = self.fc(low_freq_info)
        return x * freq_weight


# ============================================================================
# æ··åˆé—¨æŽ§åŒ…è£…å™¨
# ============================================================================

class HybridGateWrapper(nn.Module):
    """
    æ··åˆé—¨æŽ§åŒ…è£…å™¨ï¼šåŒæ—¶åº”ç”¨ spatial å’Œ frequency é—¨æŽ§
    """
    def __init__(self, base_block, spatial_gate, freq_gate):
        super().__init__()
        self.base_block = base_block
        self.spatial_gate = spatial_gate
        self.freq_gate = freq_gate
    
    def forward(self, x):
        # åŸºç¡€å—è¾“å‡º
        out = self.base_block(x)
        
        # åº”ç”¨ spatial gate
        spatial_weight = self.spatial_gate(out)  # [B, 1, H, W]
        
        # åº”ç”¨ freq gate
        freq_weight = self.freq_gate(out)  # [B, C, H, W]
        
        # æ··åˆï¼šspatial * freq * out
        return out * spatial_weight * freq_weight


# ============================================================================
# å®Œæ•´å®žçŽ°ï¼šRepHMS_FreqLALK ä¼˜åŒ–ç‰ˆï¼ˆYOLO26 å…¼å®¹ï¼‰
# ============================================================================

class RepHMS_FreqLALK_Enhanced(nn.Module):
    """
    å¢žå¼ºç‰ˆ RepHMS_FreqLALK - YOLO26 å…¼å®¹ç‰ˆ
    
    æ–°å¢žç‰¹æ€§:
    1. æ”¯æŒå¤šç§FreqGateå˜ä½“
    2. å±‚çº§åŒ–é—¨æŽ§å¼ºåº¦
    3. å¯é€‰çš„Spatial+Freqæ··åˆæ¨¡å¼
    4. âœ… å…¼å®¹ YOLO parse_model çš„å‚æ•°ä¼ é€’
    5. âœ… æ”¯æŒ c1 != c2 çš„é€šé“é€‚é…
    """
    def __init__(self, c1, c2, kernel_size=3, stride=1, depth_expansion=2, 
                 kersize=7, shortcut=True, expansion=0.5, 
                 gate_type='freq', freq_variant='adaptive'):
        """
        YOLO å…¼å®¹çš„å‚æ•°ç­¾å
        
        Args:
            c1: è¾“å…¥é€šé“æ•°ï¼ˆç”± parse_model è‡ªåŠ¨å¡«å……ï¼‰
            c2: è¾“å‡ºé€šé“æ•°ï¼ˆç”± parse_model è‡ªåŠ¨å¡«å……ï¼‰
            kernel_size: å·ç§¯æ ¸å¤§å°ï¼ˆä»Ž YAML çš„ç¬¬1ä¸ªå‚æ•°ï¼‰
            stride: æ­¥é•¿ï¼ˆä»Ž YAML çš„ç¬¬2ä¸ªå‚æ•°ï¼‰
            depth_expansion: æ·±åº¦æ‰©å±•ç³»æ•°ï¼ˆä»Ž YAML çš„ç¬¬3ä¸ªå‚æ•°ï¼‰
            kersize: LALK æ ¸å¤§å°ï¼ˆä»Ž YAML çš„ç¬¬4ä¸ªå‚æ•°ï¼‰
            shortcut: æ˜¯å¦ä½¿ç”¨å¿«æ·è¿žæŽ¥ï¼ˆä»Ž YAML çš„ç¬¬5ä¸ªå‚æ•°ï¼‰
            expansion: é€šé“æ‰©å±•ç³»æ•°ï¼ˆä»Ž YAML çš„ç¬¬6ä¸ªå‚æ•°ï¼‰
            gate_type: é—¨æŽ§ç±»åž‹ 'spatial', 'freq', 'hybrid', Noneï¼ˆä»Ž YAML çš„ç¬¬7ä¸ªå‚æ•°ï¼‰
            freq_variant: é¢‘åŸŸå˜ä½“ 'basic', 'adaptive', 'multiscale', 'hierarchical'ï¼ˆä»Ž YAML çš„ç¬¬8ä¸ªå‚æ•°ï¼‰
        """
        super().__init__()
        
        # âœ… å…³é”®ä¿®å¤ï¼šæ”¯æŒ c1 != c2
        self.channel_adapter = Conv(c1, c2, 1, 1) if c1 != c2 else nn.Identity()
        
        # ä½¿ç”¨å›ºå®šçš„ width å’Œ depthï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        self.width = 3
        self.depth = 1
        self.gate_type = gate_type
        self.freq_variant = freq_variant
        
        # åŽç»­æ‰€æœ‰æ“ä½œä½¿ç”¨ c2 ä½œä¸ºåŸºå‡†é€šé“æ•°
        c_ = int(c2 * expansion)
        c1_internal = c_ * self.width
        self.c_ = c_
        
        self.conv1 = nn.Sequential(
            nn.Conv2d(c2, c1_internal, 1, bias=False),  # æ³¨æ„è¿™é‡Œä½¿ç”¨ c2
            nn.BatchNorm2d(c1_internal),
            nn.SiLU()
        )
        
        # æž„å»ºå¤šåˆ†æ”¯çº§è”ç»“æž„
        self.RepElanMSBlock = nn.ModuleList()
        for i in range(self.width - 1):
            DepthBlock = nn.ModuleList()
            for j in range(self.depth):
                # åŸºç¡€LALKå—
                base_block = self._make_lalk_block(c_, kersize, shortcut, depth_expansion)
                
                # åœ¨æœ«ç«¯æ·»åŠ é—¨æŽ§
                if j == self.depth - 1:
                    block = self._wrap_with_gate(
                        base_block, c_, i, j,
                        gate_type, freq_variant
                    )
                else:
                    block = base_block
                
                DepthBlock.append(block)
            self.RepElanMSBlock.append(DepthBlock)
        
        out_ch = c_ * (1 + (self.width - 1) * self.depth)
        self.conv2 = nn.Sequential(
            nn.Conv2d(out_ch, c2, 1, bias=False),
            nn.BatchNorm2d(c2),
            nn.SiLU()
        )
    
    def _make_lalk_block(self, channels, kersize, shortcut, expansion):
        """åˆ›å»ºç®€åŒ–çš„LALKå—"""
        mid_ch = int(channels * expansion)
        return nn.Sequential(
            nn.Conv2d(channels, mid_ch, 1, bias=False),
            nn.BatchNorm2d(mid_ch),
            nn.SiLU(),
            nn.Conv2d(mid_ch, mid_ch, kersize, padding=kersize//2, 
                     groups=mid_ch, bias=False),
            nn.BatchNorm2d(mid_ch),
            nn.SiLU(),
            nn.Conv2d(mid_ch, channels, 1, bias=False),
            nn.BatchNorm2d(channels),
        )
    
    def _wrap_with_gate(self, base_block, channels, branch_idx, 
                       layer_idx, gate_type, freq_variant):
        """ä¸ºåŸºç¡€å—æ·»åŠ é—¨æŽ§"""
        
        if gate_type is None or gate_type == 'none':
            return base_block
        
        spatial_gate = None
        freq_gate = None
        
        # åˆ›å»º Spatial gate
        if gate_type in ['spatial', 'hybrid']:
            # ðŸ”¥ ä¿®å¤ï¼šSpatial gate ä¸å— BatchNorm å½±å“ï¼Œå› ä¸ºè¾“å‡ºåªæœ‰1ä¸ªé€šé“
            spatial_gate = nn.Sequential(
                nn.Conv2d(channels, 1, 7, padding=3, bias=False),
                nn.Sigmoid()  # ç§»é™¤ BatchNorm
            )
        
        # åˆ›å»º Freq gate
        if gate_type in ['freq', 'hybrid']:
            if freq_variant == 'adaptive':
                freq_gate = AdaptiveFreqGate(channels)
            elif freq_variant == 'multiscale':
                freq_gate = MultiScaleFreqGate(channels)
            elif freq_variant == 'hierarchical':
                freq_gate = HierarchicalFreqGate(
                    channels, layer_depth=layer_idx, max_depth=self.depth
                )
            else:  # 'basic'
                freq_gate = FreqGate(channels)
        
        # æ ¹æ®ä¸åŒæ¨¡å¼ç»„è£…
        if gate_type == 'spatial':
            return nn.Sequential(base_block, spatial_gate)
        
        elif gate_type == 'freq':
            return nn.Sequential(base_block, freq_gate)
        
        elif gate_type == 'hybrid':
            return HybridGateWrapper(base_block, spatial_gate, freq_gate)
        
        else:
            return base_block
    
    def forward(self, x):
        # âœ… ç¬¬ä¸€æ­¥ï¼šé€šé“é€‚é…
        x = self.channel_adapter(x)
        
        x = self.conv1(x)
        x_out = [x[:, i * self.c_:(i + 1) * self.c_] for i in range(self.width)]
        x_out[1] = x_out[1] + x_out[0]
        cascade = []
        elan = [x_out[0]]
        
        for i in range(self.width - 1):
            for j in range(self.depth):
                if i > 0:
                    x_out[i + 1] = x_out[i + 1] + cascade[j]
                    if j == self.depth - 1:
                        if self.depth > 1:
                            cascade = [cascade[-1]]
                        else:
                            cascade = []
                
                x_out[i + 1] = self.RepElanMSBlock[i][j](x_out[i + 1])
                elan.append(x_out[i + 1])
                
                if i < self.width - 2:
                    cascade.append(x_out[i + 1])
        
        y_out = torch.cat(elan, 1)
        y_out = self.conv2(y_out)
        return y_out


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == "__main__":
    print("ðŸ§ª æµ‹è¯• RepHMS_FreqLALK å„ä¸ªå˜ä½“ï¼ˆYOLO26 å…¼å®¹ç‰ˆï¼‰\n")
    
    # ðŸ”¥ æµ‹è¯• 1: æ ‡å‡†æƒ…å†µ (c1 == c2)
    print("=" * 60)
    print("æµ‹è¯• 1: c1 == c2 (æ ‡å‡†æƒ…å†µ)")
    print("=" * 60)
    x = torch.randn(2, 256, 40, 40)
    
    model = RepHMS_FreqLALK_Enhanced(
        c1=256, c2=256,
        kernel_size=3, stride=1, depth_expansion=2, kersize=7,
        shortcut=True, expansion=0.5,
        gate_type='freq', freq_variant='adaptive'
    )
    
    model.eval()
    with torch.no_grad():
        out = model(x)
    
    print(f"âœ… è¾“å…¥: {x.shape}")
    print(f"âœ… è¾“å‡º: {out.shape}")
    print(f"âœ… å‚æ•°é‡: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M\n")
    
    # ðŸ”¥ æµ‹è¯• 2: c1 != c2 (é€šé“é€‚é…)
    print("=" * 60)
    print("æµ‹è¯• 2: c1 != c2 (é€šé“é€‚é…)")
    print("=" * 60)
    x2 = torch.randn(2, 1536, 40, 40)  # Concat åŽçš„é€šé“æ•°
    
    model2 = RepHMS_FreqLALK_Enhanced(
        c1=1536, c2=512,  # ä¸åŒçš„è¾“å…¥è¾“å‡ºé€šé“
        kernel_size=3, stride=1, depth_expansion=2, kersize=7,
        shortcut=True, expansion=0.5,
        gate_type='freq', freq_variant='adaptive'
    )
    
    model2.eval()
    with torch.no_grad():
        out2 = model2(x2)
    
    print(f"âœ… è¾“å…¥: {x2.shape}")
    print(f"âœ… è¾“å‡º: {out2.shape}")
    print(f"âœ… å‚æ•°é‡: {sum(p.numel() for p in model2.parameters()) / 1e6:.2f}M\n")
    
    # ðŸ”¥ æµ‹è¯• 3: batch_size=1
    print("=" * 60)
    print("æµ‹è¯• 3: batch_size=1")
    print("=" * 60)
    x3 = torch.randn(1, 256, 40, 40)
    
    model3 = RepHMS_FreqLALK_Enhanced(
        c1=256, c2=256,
        kernel_size=3, stride=1, depth_expansion=2, kersize=7,
        shortcut=True, expansion=0.5,
        gate_type='freq', freq_variant='multiscale'
    )
    
    model3.eval()
    with torch.no_grad():
        out3 = model3(x3)
    
    print(f"âœ… è¾“å…¥: {x3.shape}")
    print(f"âœ… è¾“å‡º: {out3.shape}\n")
    
    # ðŸ”¥ æµ‹è¯• 4: æ‰€æœ‰å˜ä½“
    print("=" * 60)
    print("æµ‹è¯• 4: æ‰€æœ‰é¢‘åŸŸå˜ä½“")
    print("=" * 60)
    
    variants = [
        ('åŸºç¡€ç‰ˆ', 'basic'),
        ('è‡ªé€‚åº”ç‰ˆ', 'adaptive'),
        ('å¤šå°ºåº¦ç‰ˆ', 'multiscale'),
        ('å±‚çº§ç‰ˆ', 'hierarchical'),
    ]
    
    x4 = torch.randn(2, 256, 40, 40)
    
    for name, variant in variants:
        model = RepHMS_FreqLALK_Enhanced(
            c1=256, c2=256,
            gate_type='freq', freq_variant=variant
        )
        model.eval()
        with torch.no_grad():
            out = model(x4)
        
        params = sum(p.numel() for p in model.parameters()) / 1e6
        print(f"{name:12s} | è¾“å‡º: {out.shape} | å‚æ•°: {params:.2f}M")
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 60)
    print("\nðŸŽ‰ YOLO26 å…¼å®¹æ€§ä¿®å¤æ€»ç»“:")
    print("  âœ… æ”¯æŒ c1 != c2 (é€šè¿‡ channel_adapter)")
    print("  âœ… å…¼å®¹ parse_model çš„å‚æ•°ç­¾å")
    print("  âœ… ç§»é™¤äº†æ‰€æœ‰ä¼šå¯¼è‡´ batch_size=1 æŠ¥é”™çš„ BatchNorm")
    print("  âœ… ä¿®å¤äº† MultiScaleFreqGate çš„å°ºå¯¸é—®é¢˜")
    print("  âœ… æ”¯æŒæ‰€æœ‰é¢‘åŸŸå˜ä½“ï¼šbasic, adaptive, multiscale, hierarchical")
    print("\nðŸ’¡ YAML é…ç½®ç¤ºä¾‹:")
    print("  - [-1, 2, RepHMS_FreqLALK_Enhanced, [3, 1, 2, 7, True, 0.5, 'freq', 'adaptive']]")
    print("                                        â†‘å‚æ•°ä»Žè¿™é‡Œå¼€å§‹ï¼Œä¸éœ€è¦å†™ c1 å’Œ c2")