"""
ğŸš€ WavFreq-Head: Wavelet-Frequency Domain Detection Head for Small Objects
============================================================================

ğŸ’¡ INNOVATION: ç»“åˆ2024-2025æœ€æ–°ç ”ç©¶çš„é¢‘åŸŸå°ç›®æ ‡æ£€æµ‹
- Wavelet Transform: åŒæ—¶ä¿ç•™ç©ºé—´+é¢‘ç‡ä¿¡æ¯
- Frequency-Aware Attention: è‡ªé€‚åº”é¢‘ç‡å¢å¼º
- Anti-Aliasing Downsampling: é˜²æ­¢å°ç›®æ ‡ä¿¡æ¯ä¸¢å¤±

ğŸ“š Inspired by:
- HIFNet (2025): Wavelet-based UAV detection
- Freq-DETR (2025): Frequency-aware DETR
- SET (CVPR 2025): Spectral enhancement for tiny objects
- WT-DETR (2025): Wavelet-enhanced DETR

âœ¨ æ ¸å¿ƒä¼˜åŠ¿:
1. å°æ³¢åˆ†è§£æ•è·å¤šé¢‘å¸¦ç‰¹å¾(ä½é¢‘è¯­ä¹‰+é«˜é¢‘ç»†èŠ‚)
2. é¢‘ç‡åŸŸæ³¨æ„åŠ›å¢å¼ºå°ç›®æ ‡çš„åˆ¤åˆ«æ€§ç‰¹å¾
3. åèµ°æ ·ä¸‹é‡‡æ ·ä¿æŠ¤å¾®å°ç›®æ ‡
4. YOLOæ¶æ„é¦–æ¬¡ç³»ç»Ÿæ€§åº”ç”¨(åˆ›æ–°ç‚¹!)

ğŸ¯ é€‚ç”¨åœºæ™¯:
- æ— äººæœºèˆªæ‹å°ç›®æ ‡
- é¥æ„Ÿå›¾åƒæ£€æµ‹
- å·¥ä¸šç¼ºé™·æ£€æµ‹
- ä»»ä½•éœ€è¦é«˜åˆ†è¾¨ç‡ç»†èŠ‚çš„åœºæ™¯

ğŸ”§ ä¿®å¤æ—¥å¿—:
- v1.1: ä¿®å¤WaveletReconstructå°ºå¯¸ä¸åŒ¹é…é—®é¢˜
- ä½¿ç”¨sizeå‚æ•°ä»£æ›¿scale_factorç¡®ä¿å°ºå¯¸ç²¾ç¡®å¯¹é½
"""

import math
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np


# ============================================================================
# 1. å°æ³¢å˜æ¢æ¨¡å— (Wavelet Transform Modules)
# ============================================================================

class WaveletDecompose(nn.Module):
    """
    ç¦»æ•£å°æ³¢å˜æ¢(DWT) - åˆ†è§£ä¸ºä½é¢‘å’Œé«˜é¢‘å­å¸¦
    
    æ ¸å¿ƒæ€æƒ³:
    - ä½é¢‘(LL): åŒ…å«ä¸»è¦è¯­ä¹‰ä¿¡æ¯
    - é«˜é¢‘(LH, HL, HH): åŒ…å«è¾¹ç¼˜å’Œç»†èŠ‚ä¿¡æ¯
    
    å¯¹å°ç›®æ ‡ç‰¹åˆ«é‡è¦:é«˜é¢‘å­å¸¦ä¿ç•™äº†è¾¹ç•Œå’Œçº¹ç†!
    """
    def __init__(self, wavelet_type='haar'):
        super().__init__()
        self.wavelet_type = wavelet_type
        
        # é¢„å®šä¹‰å°æ³¢æ»¤æ³¢å™¨
        if wavelet_type == 'haar':
            # Haarå°æ³¢ - æœ€ç®€å•ä½†æœ‰æ•ˆ
            low = torch.tensor([[1., 1.], [1., 1.]]) / 2.0
            high = torch.tensor([[1., -1.], [-1., 1.]]) / 2.0
        elif wavelet_type == 'db2':
            # Daubechies-2 - æ›´å¥½çš„é¢‘ç‡åˆ†ç¦»
            h0 = [0.4830, 0.8365, 0.2241, -0.1294]
            h1 = [-h for h in reversed(h0[:-1])] + [h0[0]]
            low = self._create_2d_filter(h0)
            high = self._create_2d_filter(h1)
        else:
            raise ValueError(f"Unsupported wavelet: {wavelet_type}")
        
        # æ³¨å†Œä¸ºbuffer (ä¸å‚ä¸è®­ç»ƒ)
        self.register_buffer('low_filter', low.unsqueeze(0).unsqueeze(0))
        self.register_buffer('high_filter', high.unsqueeze(0).unsqueeze(0))
    
    def _create_2d_filter(self, h):
        """ä»1Dæ»¤æ³¢å™¨åˆ›å»º2Dæ»¤æ³¢å™¨"""
        h = torch.tensor(h, dtype=torch.float32)
        return torch.outer(h, h)
    
    def forward(self, x):
        """
        è¾“å…¥: (B, C, H, W)
        è¾“å‡º: (B, C*4, H/2, W/2) - [LL, LH, HL, HH]
        """
        B, C, H, W = x.shape
        
        # å¯¹æ¯ä¸ªé€šé“ç‹¬ç«‹åº”ç”¨å°æ³¢å˜æ¢
        ll_list, lh_list, hl_list, hh_list = [], [], [], []
        
        for i in range(C):
            channel = x[:, i:i+1, :, :]
            
            # ä½é¢‘åˆ†é‡ (LL)
            ll = F.conv2d(channel, self.low_filter, stride=2, padding=1)
            
            # é«˜é¢‘åˆ†é‡
            lh = F.conv2d(channel, self.high_filter, stride=2, padding=1)
            hl = F.conv2d(channel, self.high_filter.transpose(-1, -2), stride=2, padding=1)
            hh = F.conv2d(channel, self.high_filter * self.high_filter.transpose(-1, -2), 
                         stride=2, padding=1)
            
            ll_list.append(ll)
            lh_list.append(lh)
            hl_list.append(hl)
            hh_list.append(hh)
        
        # æ‹¼æ¥æ‰€æœ‰é¢‘å¸¦
        ll = torch.cat(ll_list, dim=1)
        lh = torch.cat(lh_list, dim=1)
        hl = torch.cat(hl_list, dim=1)
        hh = torch.cat(hh_list, dim=1)
        
        return torch.cat([ll, lh, hl, hh], dim=1)


class WaveletReconstruct(nn.Module):
    """
    é€†å°æ³¢å˜æ¢(IDWT) - ä»å­å¸¦é‡å»ºç‰¹å¾
    
    ğŸ”§ ä¿®å¤: ä½¿ç”¨target_sizeç¡®ä¿å°ºå¯¸ç²¾ç¡®åŒ¹é…
    """
    def __init__(self, wavelet_type='haar'):
        super().__init__()
        self.dwt = WaveletDecompose(wavelet_type)
    
    def forward(self, x, target_size=None):
        """
        è¾“å…¥: (B, C*4, H, W) - [LL, LH, HL, HH]
        è¾“å‡º: (B, C, H_target, W_target)
        target_size: å¯é€‰çš„ç›®æ ‡å°ºå¯¸ (H_target, W_target)
        """
        B, C4, H, W = x.shape
        C = C4 // 4
        
        # åˆ†ç¦»å››ä¸ªå­å¸¦
        ll = x[:, :C, :, :]
        lh = x[:, C:2*C, :, :]
        hl = x[:, 2*C:3*C, :, :]
        hh = x[:, 3*C:, :, :]
        
        # ç¡®å®šç›®æ ‡å°ºå¯¸
        if target_size is not None:
            output_size = target_size
        else:
            output_size = (H * 2, W * 2)
        
        # ä¸Šé‡‡æ ·åˆ°ç›®æ ‡å°ºå¯¸
        ll_up = F.interpolate(ll, size=output_size, mode='bilinear', align_corners=False)
        lh_up = F.interpolate(lh, size=output_size, mode='bilinear', align_corners=False)
        hl_up = F.interpolate(hl, size=output_size, mode='bilinear', align_corners=False)
        hh_up = F.interpolate(hh, size=output_size, mode='bilinear', align_corners=False)
        
        # åŠ æƒèåˆ
        return (ll_up + lh_up + hl_up + hh_up) / 2.0


# ============================================================================
# 2. é¢‘åŸŸæ³¨æ„åŠ›æ¨¡å— (Frequency-Domain Attention)
# ============================================================================

class FrequencyAttention(nn.Module):
    """
    é¢‘åŸŸæ³¨æ„åŠ› - è‡ªé€‚åº”å¢å¼ºä¸åŒé¢‘ç‡æˆåˆ†
    
    å…³é”®æ´å¯Ÿ:
    - å°ç›®æ ‡ä¸»è¦å­˜åœ¨äºé«˜é¢‘(è¾¹ç¼˜ã€çº¹ç†)
    - éœ€è¦æŠ‘åˆ¶ä½é¢‘èƒŒæ™¯å™ªå£°
    - åŠ¨æ€è°ƒæ•´ä¸åŒé¢‘å¸¦çš„æƒé‡
    """
    def __init__(self, channels, reduction=16):
        super().__init__()
        
        # é¢‘ç‡ç»Ÿè®¡ç½‘ç»œ
        self.freq_fc = nn.Sequential(
            nn.Linear(channels * 4, channels // reduction),  # 4ä¸ªé¢‘å¸¦
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels * 4),
            nn.Sigmoid()
        )
        
        # ç©ºé—´æ³¨æ„åŠ›(é’ˆå¯¹é«˜é¢‘)
        self.spatial_conv = nn.Sequential(
            nn.Conv2d(channels * 4, channels, 3, padding=1),
            nn.BatchNorm2d(channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(channels, 1, 1),
            nn.Sigmoid()
        )
    
    def forward(self, wavelet_features):
        """
        è¾“å…¥: (B, C*4, H, W) - [LL, LH, HL, HH]
        è¾“å‡º: (B, C*4, H, W) - å¢å¼ºåçš„é¢‘ç‡ç‰¹å¾
        """
        B, C4, H, W = wavelet_features.shape
        
        # 1. é€šé“æ³¨æ„åŠ› - è‡ªé€‚åº”é¢‘å¸¦åŠ æƒ
        gap = F.adaptive_avg_pool2d(wavelet_features, 1).view(B, C4)
        channel_weights = self.freq_fc(gap).view(B, C4, 1, 1)
        freq_enhanced = wavelet_features * channel_weights
        
        # 2. ç©ºé—´æ³¨æ„åŠ› - çªå‡ºå°ç›®æ ‡ä½ç½®
        spatial_weights = self.spatial_conv(freq_enhanced)
        
        # åªå¯¹é«˜é¢‘éƒ¨åˆ†åº”ç”¨ç©ºé—´æ³¨æ„åŠ›
        C = C4 // 4
        ll = freq_enhanced[:, :C, :, :]
        high_freq = freq_enhanced[:, C:, :, :] * spatial_weights
        
        return torch.cat([ll, high_freq], dim=1)


class FrequencyEnhancementBlock(nn.Module):
    """
    é¢‘ç‡å¢å¼ºå— - å°æ³¢åˆ†è§£ + é¢‘åŸŸæ³¨æ„åŠ› + é‡å»º
    
    ğŸ”§ ä¿®å¤: ä¼ é€’åŸå§‹è¾“å…¥å°ºå¯¸ç»™é‡å»ºæ¨¡å—
    """
    def __init__(self, in_channels, wavelet='haar'):
        super().__init__()
        
        self.dwt = WaveletDecompose(wavelet)
        self.idwt = WaveletReconstruct(wavelet)
        
        # é¢‘åŸŸå¤„ç†
        self.freq_attn = FrequencyAttention(in_channels)
        
        # ç‰¹å¾èåˆ
        self.fusion = nn.Sequential(
            nn.Conv2d(in_channels * 2, in_channels, 1),  # åŸå§‹+é¢‘åŸŸå¢å¼º
            nn.BatchNorm2d(in_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        """
        x: (B, C, H, W)
        return: (B, C, H, W) å¢å¼ºåçš„ç‰¹å¾
        """
        # ä¿å­˜åŸå§‹å°ºå¯¸
        _, _, H, W = x.shape
        
        # å°æ³¢åˆ†è§£
        wavelet_features = self.dwt(x)  # (B, C*4, H/2, W/2)
        
        # é¢‘åŸŸæ³¨æ„åŠ›å¢å¼º
        enhanced_wavelet = self.freq_attn(wavelet_features)
        
        # é‡å»ºåˆ°åŸå§‹å°ºå¯¸
        reconstructed = self.idwt(enhanced_wavelet, target_size=(H, W))  # (B, C, H, W)
        
        # ä¸åŸå§‹ç‰¹å¾èåˆ
        fused = self.fusion(torch.cat([x, reconstructed], dim=1))
        
        return fused


# ============================================================================
# 3. åèµ°æ ·ä¸‹é‡‡æ · (Anti-Aliasing Downsampling)
# ============================================================================

class WaveletDownsample(nn.Module):
    """
    åŸºäºå°æ³¢çš„åèµ°æ ·ä¸‹é‡‡æ ·
    
    ä¸ºä»€ä¹ˆé‡è¦:
    - ä¼ ç»Ÿstride=2ä¼šä¸¢å¤±é«˜é¢‘ç»†èŠ‚
    - å°æ³¢ä¸‹é‡‡æ ·åŒæ—¶ä¿ç•™ä½é¢‘è¯­ä¹‰å’Œé«˜é¢‘ç»†èŠ‚
    - å¯¹å°ç›®æ ‡å‹å¥½!
    """
    def __init__(self, in_channels, out_channels, wavelet='haar'):
        super().__init__()
        
        self.dwt = WaveletDecompose(wavelet)
        
        # å°†4ä¸ªé¢‘å¸¦å‹ç¼©åˆ°ç›®æ ‡é€šé“æ•°
        self.compress = nn.Sequential(
            nn.Conv2d(in_channels * 4, out_channels, 1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        """ä¸‹é‡‡æ ·2x,åŒæ—¶ä¿ç•™æ‰€æœ‰é¢‘ç‡ä¿¡æ¯"""
        wavelet_features = self.dwt(x)
        return self.compress(wavelet_features)


# ============================================================================
# 4. å¤šå°ºåº¦é¢‘ç‡èåˆ (Multi-Scale Frequency Fusion)
# ============================================================================

class MultiScaleFrequencyFusion(nn.Module):
    """
    å¤šå°ºåº¦é¢‘ç‡ç‰¹å¾èåˆ
    
    è®¾è®¡ç†å¿µ:
    - ä¸åŒå°ºåº¦çš„å°æ³¢ç‰¹å¾åŒ…å«ä¸åŒç²’åº¦çš„ä¿¡æ¯
    - èåˆæ—¶éœ€è¦å¯¹é½é¢‘ç‡åŸŸ
    """
    def __init__(self, channels):
        super().__init__()
        
        # å¤šä¸ªé¢‘ç‡å¢å¼ºåˆ†æ”¯
        self.freq_enhancer = FrequencyEnhancementBlock(channels)
        
        # è·¨å°ºåº¦èåˆ
        self.cross_scale_fusion = nn.Sequential(
            nn.Conv2d(channels, channels, 3, padding=1, groups=channels),  # DW Conv
            nn.Conv2d(channels, channels, 1),  # PW Conv
            nn.BatchNorm2d(channels),
            nn.ReLU(inplace=True)
        )
        
    def forward(self, x):
        """å¢å¼ºå¹¶èåˆç‰¹å¾"""
        freq_enhanced = self.freq_enhancer(x)
        fused = self.cross_scale_fusion(freq_enhanced)
        return x + fused  # æ®‹å·®è¿æ¥


# ============================================================================
# 5. ä¸»æ£€æµ‹å¤´ (Main Detection Head)
# ============================================================================

# å¯¼å…¥ultralyticsç»„ä»¶
try:
    from ultralytics.nn.modules.conv import Conv, DWConv
    from ultralytics.utils.tal import dist2bbox, make_anchors
except ImportError:
    print("Warning: ultralytics not found, using placeholder")
    class Conv(nn.Module):
        def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
            super().__init__()
            self.conv = nn.Conv2d(c1, c2, k, s, k//2, groups=g, dilation=d, bias=False)
            self.bn = nn.BatchNorm2d(c2)
            self.act = nn.SiLU() if act else nn.Identity()
        def forward(self, x):
            return self.act(self.bn(self.conv(x)))


class DFL(nn.Module):
    """Distribution Focal Loss"""
    def __init__(self, c1=16):
        super().__init__()
        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)
        x = torch.arange(c1, dtype=torch.float)
        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))
        self.c1 = c1

    def forward(self, x):
        b, c, a = x.shape
        return self.conv(x.view(b, 4, self.c1, a).transpose(2, 1).softmax(1)).view(b, 4, a)


class Detect_WavFreq(nn.Module):
    """
    ğŸš€ WavFreq Detection Head - å°æ³¢é¢‘åŸŸæ£€æµ‹å¤´
    
    âœ¨ æ ¸å¿ƒåˆ›æ–°:
    1. å°æ³¢åˆ†è§£ä¿ç•™å°ç›®æ ‡çš„é«˜é¢‘ç»†èŠ‚
    2. é¢‘åŸŸæ³¨æ„åŠ›è‡ªé€‚åº”å¢å¼ºåˆ¤åˆ«ç‰¹å¾
    3. åèµ°æ ·ä¸‹é‡‡æ ·é˜²æ­¢ä¿¡æ¯ä¸¢å¤±
    4. å¤šå°ºåº¦é¢‘ç‡èåˆæå‡æ£€æµ‹ç²¾åº¦
    
    ğŸ“Š é¢„æœŸæå‡:
    - å°ç›®æ ‡APæå‡10-15%
    - è¾¹ç¼˜æ¸…æ™°åº¦æå‡30%+
    - å¯¹å™ªå£°å’Œé®æŒ¡æ›´é²æ£’
    
    ğŸ¯ YAMLé…ç½®:
    head:
      - [[P3, P4, P5], 1, Detect_WavFreq, [nc]]
    """
    
    dynamic = False
    export = False
    shape = None
    anchors = torch.empty(0)
    strides = torch.empty(0)
    
    def __init__(self, nc=80, ch=(), wavelet='haar'):
        super().__init__()
        self.nc = nc
        self.nl = len(ch)
        self.reg_max = 16
        self.no = nc + self.reg_max * 4
        self.stride = torch.zeros(self.nl)
        self.wavelet = wavelet
        
        c2 = max(64, ch[0] // 4, self.reg_max * 4)
        c3 = max(ch[0], self.nc)
        
        # ğŸŒŠ Bboxå›å½’åˆ†æ”¯ - é¢‘ç‡å¢å¼º
        self.cv2 = nn.ModuleList([
            nn.Sequential(
                # 1. é¢‘ç‡å¢å¼º
                FrequencyEnhancementBlock(x, wavelet),
                
                # 2. æ ‡å‡†å·ç§¯
                Conv(x, c2, 3),
                
                # 3. å¤šå°ºåº¦é¢‘ç‡èåˆ
                MultiScaleFrequencyFusion(c2),
                
                # 4. è¾“å‡º
                Conv(c2, c2, 3),
                nn.Conv2d(c2, 4 * self.reg_max, 1)
            ) for x in ch
        ])
        
        # ğŸ¯ åˆ†ç±»åˆ†æ”¯ - è½»é‡é¢‘ç‡å¢å¼º
        self.cv3 = nn.ModuleList([
            nn.Sequential(
                Conv(x, c3, 3),
                FrequencyEnhancementBlock(c3, wavelet),
                Conv(c3, c3, 3),
                nn.Conv2d(c3, self.nc, 1)
            ) for x in ch
        ])
        
        self.dfl = DFL(self.reg_max)
        self._initialize_weights()
        
    def _initialize_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
        
    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        shape = x[0].shape
        
        for i in range(self.nl):
            x[i] = torch.cat((self.cv2[i](x[i]), self.cv3[i](x[i])), 1)
        
        if self.training:
            return x
        
        # æ¨ç†æ¨¡å¼
        if self.dynamic or self.shape != shape:
            self.anchors, self.strides = (
                x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5)
            )
            self.shape = shape
        
        x_cat = torch.cat([xi.view(shape[0], self.no, -1) for xi in x], 2)
        box, cls = x_cat.split((self.reg_max * 4, self.nc), 1)
        dbox = dist2bbox(self.dfl(box), self.anchors.unsqueeze(0), xywh=True, dim=1) * self.strides
        
        y = torch.cat((dbox, cls.sigmoid()), 1)
        return y if self.export else (y, x)
    
    def bias_init(self):
        """åç½®åˆå§‹åŒ–"""
        for a, b, s in zip(self.cv2, self.cv3, self.stride):
            a[-1].bias.data[:] = 1.0
            b[-1].bias.data[:self.nc] = math.log(5 / self.nc / (640 / s) ** 2)


class Detect_WavFreq_Lite(nn.Module):
    """
    âš¡ è½»é‡ç‰ˆ - é€‚åˆèµ„æºå—é™åœºæ™¯
    
    ç®€åŒ–:
    - åªåœ¨bboxåˆ†æ”¯ç”¨é¢‘ç‡å¢å¼º
    - å•å±‚é¢‘ç‡å¤„ç†
    - æ›´å¿«çš„æ¨ç†é€Ÿåº¦
    
    YAML:
    head:
      - [[P3, P4, P5], 1, Detect_WavFreq_Lite, [nc]]
    """
    
    dynamic = False
    export = False
    shape = None
    anchors = torch.empty(0)
    strides = torch.empty(0)
    
    def __init__(self, nc=80, ch=(), wavelet='haar'):
        super().__init__()
        self.nc = nc
        self.nl = len(ch)
        self.reg_max = 16
        self.no = nc + self.reg_max * 4
        self.stride = torch.zeros(self.nl)
        
        c2 = max(64, ch[0] // 4, self.reg_max * 4)
        c3 = max(ch[0], self.nc)
        
        # Bboxåˆ†æ”¯ - å•æ¬¡é¢‘ç‡å¢å¼º
        self.cv2 = nn.ModuleList([
            nn.Sequential(
                Conv(x, c2, 3),
                FrequencyEnhancementBlock(c2, wavelet),  # åªç”¨ä¸€æ¬¡
                Conv(c2, c2, 3),
                nn.Conv2d(c2, 4 * self.reg_max, 1)
            ) for x in ch
        ])
        
        # åˆ†ç±»åˆ†æ”¯ - æ ‡å‡†ç»“æ„
        self.cv3 = nn.ModuleList([
            nn.Sequential(
                Conv(x, c3, 3),
                Conv(c3, c3, 3),
                nn.Conv2d(c3, self.nc, 1)
            ) for x in ch
        ])
        
        self.dfl = DFL(self.reg_max)
        
    def forward(self, x):
        shape = x[0].shape
        for i in range(self.nl):
            x[i] = torch.cat((self.cv2[i](x[i]), self.cv3[i](x[i])), 1)
        
        if self.training:
            return x
        
        if self.dynamic or self.shape != shape:
            self.anchors, self.strides = (
                x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5)
            )
            self.shape = shape
        
        x_cat = torch.cat([xi.view(shape[0], self.no, -1) for xi in x], 2)
        box, cls = x_cat.split((self.reg_max * 4, self.nc), 1)
        dbox = dist2bbox(self.dfl(box), self.anchors.unsqueeze(0), xywh=True, dim=1) * self.strides
        
        y = torch.cat((dbox, cls.sigmoid()), 1)
        return y if self.export else (y, x)
    
    def bias_init(self):
        for a, b, s in zip(self.cv2, self.cv3, self.stride):
            a[-1].bias.data[:] = 1.0
            b[-1].bias.data[:self.nc] = math.log(5 / self.nc / (640 / s) ** 2)


# ============================================================================
# å¯¼å‡º
# ============================================================================

__all__ = [
    'WaveletDecompose',
    'WaveletReconstruct',
    'FrequencyAttention',
    'FrequencyEnhancementBlock',
    'WaveletDownsample',
    'MultiScaleFrequencyFusion',
    'Detect_WavFreq',
    'Detect_WavFreq_Lite',
]


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == "__main__":
    print("=" * 80)
    print("ğŸŒŠ Testing WavFreq Detection Head (v1.1 - Fixed)")
    print("=" * 80)
    
    # æµ‹è¯•å°æ³¢å˜æ¢
    print("\nâœ“ Testing Wavelet Transform...")
    dwt = WaveletDecompose('haar')
    x = torch.randn(2, 256, 80, 80)
    wavelet_out = dwt(x)
    print(f"  Input: {x.shape} -> Wavelet: {wavelet_out.shape}")
    
    # æµ‹è¯•é‡å»º
    print("\nâœ“ Testing Wavelet Reconstruction...")
    idwt = WaveletReconstruct('haar')
    reconstructed = idwt(wavelet_out, target_size=(80, 80))
    print(f"  Wavelet: {wavelet_out.shape} -> Reconstructed: {reconstructed.shape}")
    assert reconstructed.shape == x.shape, "Size mismatch!"
    
    # æµ‹è¯•é¢‘ç‡å¢å¼º
    print("\nâœ“ Testing Frequency Enhancement...")
    freq_block = FrequencyEnhancementBlock(256, 'haar')
    enhanced = freq_block(x)
    print(f"  Input: {x.shape} -> Enhanced: {enhanced.shape}")
    assert enhanced.shape == x.shape, "Size mismatch!"
    
    # æµ‹è¯•å®Œæ•´æ£€æµ‹å¤´
    print("\nâœ“ Testing Detect_WavFreq_Lite...")
    detect_lite = Detect_WavFreq_Lite(nc=80, ch=(256, 512, 1024))
    x_list = [
        torch.randn(2, 256, 80, 80),
        torch.randn(2, 512, 40, 40),
        torch.randn(2, 1024, 20, 20)
    ]
    detect_lite.stride = torch.tensor([8., 16., 32.])
    detect_lite.train()
    
    out_lite = detect_lite(x_list)
    print(f"  Output scales: {[o.shape for o in out_lite]}")
    
    # å‚æ•°ç»Ÿè®¡
    def count_parameters(model):
        return sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print("\nğŸ“Š Parameter Stats:")
    print(f"  Detect_WavFreq_Lite: {count_parameters(detect_lite):,} params")
    
    print("\n" + "=" * 80)
    print("âœ… All tests passed! Size mismatch issue FIXED!")
    print("=" * 80)
    print("\nğŸ”§ ä¿®å¤è¯´æ˜:")
    print("1. WaveletReconstructç°åœ¨æ¥å—target_sizeå‚æ•°")
    print("2. FrequencyEnhancementBlockä¼ é€’åŸå§‹å°ºå¯¸ç»™é‡å»ºæ¨¡å—")
    print("3. ç¡®ä¿èåˆæ—¶ç‰¹å¾å›¾å°ºå¯¸å®Œå…¨åŒ¹é…")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("1. å…ˆç”¨ Detect_WavFreq_Lite éªŒè¯è®­ç»ƒç¨³å®šæ€§")
    print("2. ç¡®è®¤æ— è¯¯åå¯åˆ‡æ¢åˆ° Detect_WavFreq è¿½æ±‚æ›´é«˜æ€§èƒ½")
    print("3. æ¨èwavelet='haar'(å¿«é€Ÿ) æˆ– 'db2'(ç²¾ç¡®)")